{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "name": "10-4(colab).Korean-text-analysis-visualization-4-movie-data-analysis",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibk25244/su-ai/blob/master/10_4(colab)_Korean_text_analysis_visualization_4_movie_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ja1-BWO3w9",
        "colab_type": "text"
      },
      "source": [
        "- - -\n",
        "\n",
        "<font size=6 color='tomato'>한글 텍스트 분석 및 시각화 - <font color='royalblue'>4 단계 : 데이터 분석</font>   \n",
        "<font size=5 color='purple'>Korean Text Analysis & Visualization - <font color='forestgreen'>Step 4: Data Analysis</font>\n",
        "\n",
        "* * *\n",
        "\n",
        "**<font size=4>박 진 수</font>** 교수  \n",
        "Intelligent Data Semantics Lab  \n",
        "Seoul National University\n",
        "\n",
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QT4nnt8Rwgg",
        "colab_type": "toc"
      },
      "source": [
        ">[텍스트 분석 절차](#scrollTo=oA1Fvl8NO3w-)\n",
        "\n",
        ">[추가 영화 리뷰 데이터 수집하기](#scrollTo=1IcxbrP2O3xD)\n",
        "\n",
        ">[영화 리뷰 간 초간단 유사성 계산하기](#scrollTo=mnr8cjbkO3xP)\n",
        "\n",
        ">>[앞 장에서 저장한 파일을 불러온다.](#scrollTo=jtGf6Uk9itCj)\n",
        "\n",
        ">>>[(방법 1) 로컬 파일 업로드 하여 열기](#scrollTo=D0uivRGO6l5V)\n",
        "\n",
        ">>>[(방법 2) 데이터 파일 내려받아 열기](#scrollTo=PjAWBCyc69Yj)\n",
        "\n",
        ">>[분석을 위해 파일들을 전처리하기](#scrollTo=k8ShNpK2k5V3)\n",
        "\n",
        ">>[유사성 분석](#scrollTo=pXONMcJ8w9IO)\n",
        "\n",
        ">[한글 형태소 분석 후 유사도 계산하기](#scrollTo=8xM5evGxO3xT)\n",
        "\n",
        ">[THE END](#scrollTo=IrfNtoLBO3xY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA1Fvl8NO3w-",
        "colab_type": "text"
      },
      "source": [
        "# 텍스트 분석 절차"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rlprr2NpJGgG"
      },
      "source": [
        "**1** 단계 - **데이터 수집**\n",
        "- 웹, SNS 등에서 분석에 필요한 데이터를 수집한다.\n",
        "- 이미 데이터가 있으면 이 단계는 생략할 수 있다.\n",
        "\n",
        "**2** 단계 - **데이터 전처리**\n",
        "- 자연어를 기계가 이해할 수 있는 인공어(artificial language)로 번역한다.\n",
        "- Tokenization, POS Tagging(형태소 분석), Pruning 등 \n",
        "\n",
        "**3** 단계 - **데이터 탐색**\n",
        "- 분석의 방향성을 제시하기 위해 전처리한 데이터를 탐색한다.\n",
        "- 일반적으로는 단어의 출현 빈도(frequency)를 기반으로 탐색한다.\n",
        "\n",
        "**<font size='+3'>4 단계 - 데이터 분석</font>**\n",
        "- 텍스트 데이터를 통해 유의미한 정보를 추출하는 분석을 수행한다.\n",
        "- 감성분석, 토픽모델, 머신러닝 등\n",
        "\n",
        "**5** 단계 - **인사이트 도출**\n",
        "- 경영 환경에서 효과적인 의사 결정에 도움을 줄 수 있는 인사이트를 도출한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IcxbrP2O3xD",
        "colab_type": "text"
      },
      "source": [
        "# 추가 영화 리뷰 데이터 수집하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_BDjD96z27q",
        "colab_type": "text"
      },
      "source": [
        "앞서 수집한 영화 리뷰('비긴 어게인(2013)') 데이터와 비교할 영화 **2**편을 선정하여 리뷰 데이터를 수집한다.\n",
        "\n",
        "이 실습에서 사용할 추가 영화는 '라라랜드(2016)'와 '베테랑(2014)'이다.\n",
        "- '라라랜드(2016)'의 ID는 **95306**\n",
        "- '베테랑(2014)'의 ID는 **81734**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw8v0XZg1cUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib\n",
        "\n",
        "# --- 해당 영화 리뷰의 첫 페이지를 가져온다.\n",
        "# URL만 바꾸면 다른 영화 리뷰 데이터 수집할 수 있다.\n",
        "url = __TODO__ \n",
        "\n",
        "bs = BeautifulSoup(urlopen(url), 'html.parser')  # 'html5lib'\n",
        "\n",
        "# -- 리뷰를 작성한 전체 네티즌의 인원을 담고 있는 태그를 가져온다\n",
        "reviewers = bs.find(__TODO__)\n",
        "\n",
        "# --- 총 리뷰 개수를 10으로 나누어 페이지 개수를 계산할 수 있다.\n",
        "total = __TODO__\n",
        "\n",
        "# --- 총 페이지 수를 계산한다.\n",
        "# 총 평점 개수를 10으로 나누고 정수로 변환해 총 페이지 개수를 계산한다.\n",
        "# 10으로 나누는 이유는 한 페이지당 평점이 10개씩 있어서 그렇다.\n",
        "__TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5JLQ5m02B02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- 모든 리뷰를 가져온다.\n",
        "# 만약 빠른 분석을 하려면 최대 10 페이지의 리뷰만 받아온다.\n",
        "# page_no = 10 if page_no > 10 else page_no\n",
        "\n",
        "grades = []                   # 태그를 제거한 리뷰 평점 전체를 담을 리스트를 초기화한다.\n",
        "reviews = []                  # 태그를 제거한 리뷰 전체를 담을 리스트를 초기화한다.\n",
        "\n",
        "try:\n",
        "    for i in range(page_no):  # 총 리뷰 페이지만큼 순환문을 사용해서 전체 리뷰를 가져온다.   \n",
        "        url = __TODO__ \n",
        "        bs = BeautifulSoup(urlopen(url), 'html.parser')  # 'html5lib'\n",
        "\n",
        "        # --- find_all(name, attrs, recursive, string, limit, **kwargs)메소드를 통해 모든 리뷰와 평점을 추출한다.\n",
        "        # 태그를 제거한 해당 페이지의 네티즌 평점을 리스트에 추가한다.\n",
        "        grades += [grade.get_text() for grade in bs.find_all(__TODO__)]\n",
        "        # 태그를 제거한 해당 페이지의 네티즌 리뷰를 리스트에 추가한다.\n",
        "        reviews += [review.get_text(strip=True) for review in bs.find_all(__TODO__)]\n",
        "\n",
        "        # 진행 사항을 표시한다.\n",
        "        print('.', end='')\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f' 현재 가져온 리뷰 개수: {len(reviews):,}')\n",
        "    else:\n",
        "        print('\\n=======', 'Job completed!', '=' * 25)\n",
        "        print(f'총 리뷰 개수.......: {len(reviews):,}개')\n",
        "        print(f'총 리뷰 평점 개수...: {len(grades):,}개')\n",
        "except urllib.error.HTTPError as err:\n",
        "    print('The server returned an HTTP error:', err)\n",
        "except urllib.error.URLError as err:\n",
        "    print('The server could not be found!', err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYO8suaZ2Fga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- 가져온 내용을 파일로 저장한다.\n",
        "path = 'movie-reviews-B.txt'\n",
        "# path = 'movie-reviews-C.txt'\n",
        "\n",
        "# 텍스트 파일을 쓰기 모드로 연다.\n",
        "# 이 때 빈 리뷰와 평점은 파일로 저장하지 않는다.\n",
        "with open(path, mode='w', encoding='utf-8') as file:\n",
        "  __TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p5QTyZKU-PkY",
        "colab": {}
      },
      "source": [
        "# ======= For Google Colaboratory ===============================\n",
        "# --- 수집한 데이터와 전처리한 데이터를 로컬 파일로 내려받기를 한다.\n",
        "from google.colab import files\n",
        "files.download(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnr8cjbkO3xP",
        "colab_type": "text"
      },
      "source": [
        "# 영화 리뷰 간 초간단 유사성 계산하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jtGf6Uk9itCj"
      },
      "source": [
        "## 앞 장에서 저장한 파일을 불러온다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0uivRGO6l5V",
        "colab_type": "text"
      },
      "source": [
        "### (방법 1) 로컬 파일 업로드 하여 열기\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G7Xclhz9tVxv",
        "colab": {}
      },
      "source": [
        "# ===== 만약 파일을 로컬 파일로 저장했다면 =============================================\n",
        "# --- Importing a local file\n",
        "from google.colab import files\n",
        "\n",
        "# 앞서 수집한 영화 리뷰 파일('movie-reviews-A.txt')을 업로드한다.\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드한 파일을 읽어서 메모리에 저장한다.\n",
        "text = uploaded[tuple(uploaded)[0]].decode('utf-8').splitlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjAWBCyc69Yj",
        "colab_type": "text"
      },
      "source": [
        "### (방법 2) 데이터 파일 내려받아 열기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTd3r_8iYKGw",
        "colab_type": "text"
      },
      "source": [
        "실습을 위해 저장해둔 파일을 내려받도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bAe-dHkYLgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q --show-progress --no-check-certificate https://raw.githubusercontent.com/snu-ds/data/master/movie-reviews-begin-again.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8ShNpK2k5V3",
        "colab_type": "text"
      },
      "source": [
        "## 분석을 위해 파일들을 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erd1dR7hrh-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 분석에 앞서 크롤링했던 영화 리뷰 데이터 불러온다.\n",
        "filenames = ('movie-reviews-A.txt',\n",
        "             'movie-reviews-B.txt',\n",
        "             'movie-reviews-C.txt')\n",
        "\n",
        "# 각 영화 리뷰 데이터를 담기 위한 변수를 초기화 한다.\n",
        "corpus = []\n",
        "\n",
        "for path in filenames:\n",
        "  corpus += ['\\n'.join([line.split('|')[1]\n",
        "                for line in open(path, mode='r', \n",
        "                                 encoding='utf-8').read().splitlines()])]\n",
        "else:\n",
        "  print(len(corpus))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMUB39fork1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus[0][:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_F7GhQmrqL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus[1][:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Ry5kwkO3xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus[2][:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXONMcJ8w9IO",
        "colab_type": "text"
      },
      "source": [
        "## 유사성 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bN021UY2kyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sklearn 패키지에서 TfidfVectorizer를 불러온다.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\t\n",
        "\n",
        "# TfidfVectorizer 객체를 생성한다.\n",
        "vectorizer = __TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFF36ZDP2lz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- 영화 리뷰 데이터 3개를 벡터 공간에 투사한다.\n",
        "# fit_transform()를 통해 corpus의 텍스트 데이터를 벡터화해 변수에 할당한다.\n",
        "X = __TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUV1A_T02w4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- 벡터 연산을 용이하게 하기 위해 벡터를 행렬에서 0이 적게 나오도록 dense하게 만든다. \n",
        "# dense한 matrix로 변환한다.\n",
        "# 결과로 n차원(n : unique 한 단어의 개수) 공간 상의 세 개의 벡터(각각 하나의 영화의 리뷰를 표상)를 구성한다.\n",
        "# 이 세 개의 벡터 연산을 통해 각 영화 (리뷰) 간의 관계를 도출해 낼 수 있다.\n",
        "X = __TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W7YP07826v2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sklearn 패키지에서 cosine_similarity() 불러오기 (코사인 유사도 계산)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- 영화 리뷰 간 유사성(cosine similarity)을 계산한다.\n",
        "print(\"'영화 A' & '영화 B'의 유사성:\\t\", cosine_similarity(__TODO__))\n",
        "print(\"'영화 A' & '영화 C'의 유사성:\\t\", cosine_similarity(__TODO__))\n",
        "print(\"'영화 B' & '영화 C'의 유사성:\\t\", cosine_similarity(__TODO__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xM5evGxO3xT",
        "colab_type": "text"
      },
      "source": [
        "# 한글 형태소 분석 후 유사도 계산하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8-ViHJzO1k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ======= 형태소 분석을 위해 한글 분석 모듈 konlpy를 설치한다. =============\n",
        "!python -m pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJqRkbOZO1k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import konlpy \n",
        "print('KoNLPy version...:', konlpy.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS3iBcHHO3xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open Korean Text\n",
        "from konlpy.tag import Okt \n",
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFMiOaAXvEif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 분석을 위해 각 리뷰 마지막에 붙인 새줄바꿈 문자를 모두 제거한다.\n",
        "corpus = [c.replace('\\n', '') for c in corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFFQIeig3BrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 형태소(Part-of-Speech)별로 추출하되 토큰을 정규화하고 어간 단위로 구분한다.\n",
        "pos_corpus = __TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fbDzynOuneA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_corpus[0][:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MND8-qUuvED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_corpus[1][:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEnuw7SdvuHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_corpus[2][:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3uk_qrg3CxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sklearn 패키지에서 TfidfVectorizer를 불러온다.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\t\n",
        "\n",
        "# TfidfVectorizer 객체를 생성한다.\n",
        "vectorizer = __TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_pUBtbr3JI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- 영화 리뷰 데이터 3개를 벡터 공간에 투사한다.\n",
        "# fit_transform()를 통해 corpus의 텍스트 데이터를 벡터화해 변수에 할당한다.\n",
        "Y = __TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1SWjylo3OYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- 벡터 연산을 용이하게 하기 위해 벡터를 행렬에서 0이 적게 나오도록 dense하게 만든다. \n",
        "# dense한 matrix로 변환한다.\n",
        "# 결과로 n차원(n : unique 한 단어의 개수) 공간 상의 세 개의 벡터(각각 하나의 영화의 리뷰를 표상)를 구성한다.\n",
        "# 이 세 개의 벡터 연산을 통해 각 영화 (리뷰) 간의 관계를 도출해 낼 수 있다.\n",
        "Y = __TODO__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyUCvUhP3Tf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sklearn 패키지에서 cosine_similarity() 불러오기 (코사인 유사도 계산)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- 영화 리뷰 간 유사성(cosine similarity)을 계산한다.\n",
        "print(\"'영화 A' & '영화 B'의 유사성:\\t\", cosine_similarity(__TODO__))\n",
        "print(\"'영화 A' & '영화 C'의 유사성:\\t\", cosine_similarity(__TODO__))\n",
        "print(\"'영화 B' & '영화 C'의 유사성:\\t\", cosine_similarity(__TODO__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrfNtoLBO3xY",
        "colab_type": "text"
      },
      "source": [
        "- - -\n",
        "# <font color='red'>THE END</font>"
      ]
    }
  ]
}